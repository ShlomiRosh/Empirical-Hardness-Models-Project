{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"DataGenerator.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"MYgdWlKTOxqH"},"source":["----------------------------------------------------\r\n","# **Introduction to Optimization - Project.**\r\n","----------------------------------------------------"]},{"cell_type":"code","metadata":{"id":"9OeZlJCKUlVF"},"source":["# Import the standard libraries of pandas.\r\n","\r\n","import pandas as pd\r\n","import matplotlib.pyplot as plt\r\n","%matplotlib inline\r\n","import seaborn as sns\r\n","import warnings\r\n","warnings. filterwarnings(\"ignore\")\r\n","sns.set_style('whitegrid')\r\n","from google.colab import files"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":575},"id":"dSVmsDqtkcgV","executionInfo":{"status":"ok","timestamp":1610890170574,"user_tz":-120,"elapsed":16215,"user":{"displayName":"SHALOM RO","photoUrl":"","userId":"10247544416664521753"}},"outputId":"600079c0-7b81-493f-8555-f354ac8b8919"},"source":["# Install the solver and import its libraries, in addition import all the\r\n","# libraries with which we will prepare the features.\r\n","\r\n","!pip3 install ortools \r\n","!pip install python-igraph\r\n","\r\n","from ortools.constraint_solver import routing_enums_pb2\r\n","from ortools.constraint_solver import pywrapcp\r\n","\r\n","import numpy as np\r\n","import time\r\n","import random \r\n","from random import randrange\r\n","from scipy import stats\r\n","from scipy.stats import skew\r\n","from scipy.sparse import csr_matrix\r\n","from scipy.sparse.csgraph import minimum_spanning_tree\r\n","from scipy.sparse.csgraph import depth_first_tree\r\n","from igraph import Graph, mean\r\n","import igraph\r\n","import itertools\r\n","import math"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting ortools\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/63/94/2832edee6f4fb4e77e8585b6034f9506be24361fe6ead4e76de38ab0a666/ortools-8.1.8487-cp36-cp36m-manylinux1_x86_64.whl (14.0MB)\n","\u001b[K     |████████████████████████████████| 14.0MB 322kB/s \n","\u001b[?25hCollecting absl-py>=0.11\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bc/58/0aa6fb779dc69cfc811df3398fcbeaeefbf18561b6e36b185df0782781cc/absl_py-0.11.0-py3-none-any.whl (127kB)\n","\u001b[K     |████████████████████████████████| 133kB 59.9MB/s \n","\u001b[?25hCollecting protobuf>=3.14.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fe/fd/247ef25f5ec5f9acecfbc98ca3c6aaf66716cf52509aca9a93583d410493/protobuf-3.14.0-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n","\u001b[K     |████████████████████████████████| 1.0MB 51.5MB/s \n","\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from absl-py>=0.11->ortools) (1.15.0)\n","\u001b[31mERROR: tensorflow-metadata 0.26.0 has requirement absl-py<0.11,>=0.9, but you'll have absl-py 0.11.0 which is incompatible.\u001b[0m\n","Installing collected packages: absl-py, protobuf, ortools\n","  Found existing installation: absl-py 0.10.0\n","    Uninstalling absl-py-0.10.0:\n","      Successfully uninstalled absl-py-0.10.0\n","  Found existing installation: protobuf 3.12.4\n","    Uninstalling protobuf-3.12.4:\n","      Successfully uninstalled protobuf-3.12.4\n","Successfully installed absl-py-0.11.0 ortools-8.1.8487 protobuf-3.14.0\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["google"]}}},"metadata":{"tags":[]}},{"output_type":"stream","text":["Collecting python-igraph\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/20/6e/3ac2fc339051f652d4a01570d133e4d15321aaec929ffb5f49a67852f8d9/python_igraph-0.8.3-cp36-cp36m-manylinux2010_x86_64.whl (3.2MB)\n","\u001b[K     |████████████████████████████████| 3.2MB 7.6MB/s \n","\u001b[?25hCollecting texttable>=1.6.2\n","  Downloading https://files.pythonhosted.org/packages/06/f5/46201c428aebe0eecfa83df66bf3e6caa29659dbac5a56ddfd83cae0d4a4/texttable-1.6.3-py2.py3-none-any.whl\n","Installing collected packages: texttable, python-igraph\n","Successfully installed python-igraph-0.8.3 texttable-1.6.3\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"QhBlK-HFe9YV"},"source":["## **In this section we create an instance of TSP**\r\n","## **solve it and produce for it the following features:**\r\n","* **Mean** - Average weights of the distance matrix.\r\n","* **Std** - Standard Deviation of the distance matrix.\r\n","* **Skewness** - What is the tendency of the weights in the distance matrix.\r\n","* **Noc** - Number of cities we have in the distance matrix [matrix dimension].\r\n","* **Td** - The total distance of the solution rout.\r\n","* **Dmft** - Distance matrix features time, That is how long it took us to calculate all these features.\r\n","* **MST_Mean** - Average weights of the MST.\r\n","* **MST_Std** - Standard Deviation of the MST.\r\n","* **MST_Skewness** - What is the tendency of the weights in the MST.\r\n","* **MST_ft** - MST features time, That is how long it took us to calculate the MST & all these features.\r\n","* **D_Mean** - Average degree of the MST.\r\n","* **D_Std** - Standard Deviation of the MST degrees.\r\n","* **D_Skewness** - What is the tendency of the degrees in the MST.\r\n","* **DFT_Mean** - The average weight of the deepest track in MST.\r\n","* **DFT_Std** - Standard Deviation of the deepest track in MST.\r\n","* **DFT_Max** - The heaviest arch on the longest route in MST.\r\n","* **DDFT_ft** - Degree & DFT features time, That is how long it took us to calculate all these features.\r\n","\r\n"]},{"cell_type":"code","metadata":{"id":"ERWE9rpBU5Jd"},"source":["# Simple travelling salesman problem between cities - solver OR Tools By Google. \r\n","\r\n","def create_data_model():\r\n","    # Stores the data for the problem. \r\n","    data = {}\r\n","    # dim will be the number of Vertices\\Cities in the Traveling Salesman Problem.\r\n","    # Randomly select the matrix dimension in unifom distribution.\r\n","    dim = np.random.randint(10, 350) \r\n","    # Generate a square symmetric matrix It will be the distance matrix that the solver will solve.\r\n","    square_matrice = [[0 for row in range(dim)] for col in range(dim)]\r\n","    for i in range(dim):\r\n","        for j in range(dim):\r\n","            if i == j:\r\n","                square_matrice[i][j] = 0\r\n","            else:\r\n","                # Randomly fill the matrix in unifom distribution.\r\n","                square_matrice[i][j] = square_matrice[j][i] = np.random.randint(1, 1000) \r\n","    data['distance_matrix'] = square_matrice # yapf: disable\r\n","    data['num_vehicles'] = 1\r\n","    data['depot'] = 0\r\n","    return data\r\n","\r\n","\r\n","def main():\r\n","    # Start measuring solution time.\r\n","    start_time = time.time()\r\n","    # Instantiate the data problem.\r\n","    data = create_data_model()\r\n","    # Create the routing index manager.\r\n","    manager = pywrapcp.RoutingIndexManager(len(data['distance_matrix']),\r\n","                                           data['num_vehicles'], data['depot'])\r\n","    # Create Routing Model.\r\n","    routing = pywrapcp.RoutingModel(manager)\r\n","    def distance_callback(from_index, to_index):\r\n","        # Returns the distance between the two nodes. \r\n","        # Convert from routing variable Index to distance matrix NodeIndex.\r\n","        from_node = manager.IndexToNode(from_index)\r\n","        to_node = manager.IndexToNode(to_index)\r\n","        return data['distance_matrix'][from_node][to_node]\r\n","    transit_callback_index = routing.RegisterTransitCallback(distance_callback)\r\n","    # Define cost of each arc.\r\n","    routing.SetArcCostEvaluatorOfAllVehicles(transit_callback_index)\r\n","    # Setting first solution heuristic.\r\n","    search_parameters = pywrapcp.DefaultRoutingSearchParameters()\r\n","    search_parameters.first_solution_strategy = (\r\n","        routing_enums_pb2.FirstSolutionStrategy.PATH_CHEAPEST_ARC)\r\n","    # Solve the problem.\r\n","    solution = routing.SolveWithParameters(search_parameters)\r\n","    solution_time = time.time() - start_time\r\n","\r\n","    '''In this part of the code we will create the following features on the distance matrix of the problem.\r\n","    *  Mean - Average weights of the distance matrix.\r\n","    *  Std - Standard Deviation of the distance matrix.\r\n","    *  Skewness  - What is the tendency of the weights in the distance matrix.\r\n","    *  Noc - Number of cities we have in the distance matrix [matrix dimension].\r\n","    *  Td - The total distance of the solution rout. \r\n","    *  Dmft - Distance matrix features time, That is how long it took us to calculate all these features.\r\n","    '''\r\n","    dmt_start_time = time.time()\r\n","    mat = np.array(data['distance_matrix'])\r\n","    mean = mat.mean()\r\n","    std = mat.std()\r\n","    merged = list(itertools.chain(*mat))\r\n","    skewness = skew(merged)\r\n","    noc = len(data['distance_matrix'])\r\n","    td = solution.ObjectiveValue() if solution else -1\r\n","    dmft = time.time() - dmt_start_time\r\n","\r\n","    '''In this part of the code we will create from the distance matrix of the problem an MST and than\r\n","    on the MST we take the following features.\r\n","    *  MST_Mean - Average weights of the MST.\r\n","    *  MST_Std - Standard Deviation of the MST.\r\n","    *  MST_Skewness  - What is the tendency of the weights in the MST.\r\n","    *  MST_ft - MST features time, That is how long it took us to calculate the MST & all these features.\r\n","    '''\r\n","    spt_start_time = time.time()\r\n","    X = csr_matrix(mat)\r\n","    Tcsr = minimum_spanning_tree(X)\r\n","    mat_st = np.array(Tcsr.toarray().astype(int))\r\n","    mst_mean = mat_st.mean()\r\n","    mst_std = mat_st.std()\r\n","    merged_st = list(itertools.chain(*mat_st))\r\n","    mst_skewness = skew(merged_st)\r\n","    mst_ft = time.time() - spt_start_time\r\n","\r\n","    '''In this part of the code we calculate features from the MST that are considered to be\r\n","    related to the rank and depth of the tracks in it.\r\n","    *  D_Mean - Average degree of the MST.\r\n","    *  D_Std - Standard Deviation of the MST degrees.\r\n","    *  D_Skewness  - What is the tendency of the degrees in the MST.\r\n","    *  DFT_Mean - The average weight of the deepest track in MST.\r\n","    *  DFT_Std - Standard Deviation of the deepest track in MST.\r\n","    *  DFT_Max - The heaviest arch on the longest route in MST.\r\n","    *  DDFT_ft - Degree & DFT features time, That is how long it took us to calculate all these features.\r\n","    '''\r\n","    dstt_start_time = time.time()\r\n","    g = Graph.Weighted_Adjacency(mat_st.tolist())\r\n","    d_mean = igraph.statistics.mean(g.degree())\r\n","    d_std = igraph.statistics.sd(g.degree())\r\n","    d_skewness = skew(g.degree())\r\n","    d_t = depth_first_tree(X, 0, directed=False)\r\n","    mat_dt = np.array(d_t.toarray().astype(int))\r\n","    dft_mean = mat_dt.mean()\r\n","    dft_std = mat_dt.std()\r\n","    dft_max = np.amax(mat_dt)\r\n","    ddft_ft = time.time() - dstt_start_time\r\n","\r\n","    # In this map we will hold all the features and their results.\r\n","    features_map = {'Mean': mean, 'Std': std, 'Skewness': skewness, 'Noc': noc, 'Td': td, 'Dmft': dmft,\r\n","                    'MST_Mean': mst_mean, 'MST_Std': mst_std, 'MST_Skewness': mst_skewness, 'MST_ft': mst_ft,\r\n","                    'D_Mean': d_mean, 'D_Std': d_std, 'D_Skewness': d_skewness, 'DFT_Mean': dft_mean,'DFT_Std': dft_std,\r\n","                    'DFT_Max': dft_max, 'DDFT_ft': ddft_ft, 'Solution_time': solution_time}\r\n","\r\n","    return features_map"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dQ2DweSUTm2p"},"source":["# Main    \r\n","# Create dataFrame.\r\n","data_TSP = pd.DataFrame()\r\n","# Fill the dataFrame.\r\n","for i in range(10000):\r\n","    #print(i)\r\n","    features_map = main()\r\n","    data_TSP = data_TSP.append(features_map, ignore_index=True) "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":222},"id":"lDWFHDXdmneu","executionInfo":{"status":"ok","timestamp":1610909647501,"user_tz":-120,"elapsed":12501916,"user":{"displayName":"SHALOM RO","photoUrl":"","userId":"10247544416664521753"}},"outputId":"97b4c38d-4ffb-4f43-f924-42131d59bded"},"source":["# Show data frame.\r\n","\r\n","data_TSP.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>DDFT_ft</th>\n","      <th>DFT_Max</th>\n","      <th>DFT_Mean</th>\n","      <th>DFT_Std</th>\n","      <th>D_Mean</th>\n","      <th>D_Skewness</th>\n","      <th>D_Std</th>\n","      <th>Dmft</th>\n","      <th>MST_Mean</th>\n","      <th>MST_Skewness</th>\n","      <th>MST_Std</th>\n","      <th>MST_ft</th>\n","      <th>Mean</th>\n","      <th>Noc</th>\n","      <th>Skewness</th>\n","      <th>Solution_time</th>\n","      <th>Std</th>\n","      <th>Td</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.002684</td>\n","      <td>994.0</td>\n","      <td>4.281241</td>\n","      <td>53.119427</td>\n","      <td>1.983051</td>\n","      <td>0.991500</td>\n","      <td>1.132149</td>\n","      <td>0.004528</td>\n","      <td>0.079216</td>\n","      <td>17.508554</td>\n","      <td>1.068120</td>\n","      <td>0.005651</td>\n","      <td>503.054007</td>\n","      <td>118.0</td>\n","      <td>-0.039861</td>\n","      <td>0.269456</td>\n","      <td>292.236114</td>\n","      <td>2616.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.004046</td>\n","      <td>997.0</td>\n","      <td>2.391274</td>\n","      <td>39.626311</td>\n","      <td>1.990148</td>\n","      <td>1.196133</td>\n","      <td>1.067013</td>\n","      <td>0.010491</td>\n","      <td>0.031838</td>\n","      <td>21.608326</td>\n","      <td>0.541832</td>\n","      <td>0.013047</td>\n","      <td>500.059453</td>\n","      <td>203.0</td>\n","      <td>-0.014632</td>\n","      <td>1.373102</td>\n","      <td>289.733257</td>\n","      <td>3185.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.006801</td>\n","      <td>994.0</td>\n","      <td>1.732715</td>\n","      <td>34.118103</td>\n","      <td>1.993127</td>\n","      <td>0.854827</td>\n","      <td>1.003419</td>\n","      <td>0.020711</td>\n","      <td>0.016698</td>\n","      <td>31.544559</td>\n","      <td>0.363748</td>\n","      <td>0.029591</td>\n","      <td>499.979240</td>\n","      <td>291.0</td>\n","      <td>-0.010912</td>\n","      <td>2.116377</td>\n","      <td>288.761128</td>\n","      <td>3643.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.007278</td>\n","      <td>995.0</td>\n","      <td>1.592935</td>\n","      <td>32.389269</td>\n","      <td>1.993528</td>\n","      <td>1.213399</td>\n","      <td>1.122363</td>\n","      <td>0.023446</td>\n","      <td>0.013615</td>\n","      <td>30.368070</td>\n","      <td>0.297845</td>\n","      <td>0.033800</td>\n","      <td>498.676407</td>\n","      <td>309.0</td>\n","      <td>0.003925</td>\n","      <td>2.001439</td>\n","      <td>290.388494</td>\n","      <td>3714.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.006666</td>\n","      <td>999.0</td>\n","      <td>1.688561</td>\n","      <td>33.446180</td>\n","      <td>1.993220</td>\n","      <td>1.417943</td>\n","      <td>1.121810</td>\n","      <td>0.021590</td>\n","      <td>0.014318</td>\n","      <td>28.048382</td>\n","      <td>0.302933</td>\n","      <td>0.027265</td>\n","      <td>496.423625</td>\n","      <td>295.0</td>\n","      <td>0.012855</td>\n","      <td>2.972457</td>\n","      <td>289.502941</td>\n","      <td>3534.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["    DDFT_ft  DFT_Max  DFT_Mean  ...  Solution_time         Std      Td\n","0  0.002684    994.0  4.281241  ...       0.269456  292.236114  2616.0\n","1  0.004046    997.0  2.391274  ...       1.373102  289.733257  3185.0\n","2  0.006801    994.0  1.732715  ...       2.116377  288.761128  3643.0\n","3  0.007278    995.0  1.592935  ...       2.001439  290.388494  3714.0\n","4  0.006666    999.0  1.688561  ...       2.972457  289.502941  3534.0\n","\n","[5 rows x 18 columns]"]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"id":"Mm86NRFWAp_r","executionInfo":{"status":"ok","timestamp":1610909649152,"user_tz":-120,"elapsed":1567,"user":{"displayName":"SHALOM RO","photoUrl":"","userId":"10247544416664521753"}},"outputId":"591c3cc5-3efa-46e7-ca3d-643f99ddd081"},"source":["data_TSP.to_csv('data_10000.csv')\r\n","files.download('data_10000.csv')"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"application/javascript":["download(\"download_03d68f2c-8f3a-44ce-89b3-140bc0368c2d\", \"data_10000.csv\", 3134277)"],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{"tags":[]}}]}]}